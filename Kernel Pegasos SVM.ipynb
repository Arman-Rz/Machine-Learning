{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb66c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e50c35",
   "metadata": {},
   "source": [
    "# Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df668b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3cbcae",
   "metadata": {},
   "source": [
    "# Preparing data:\n",
    "1. Seperating features and labels\n",
    "2. Normalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee51843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataNormalize(inputData):\n",
    "    mean = np.mean(inputData, axis = 0)\n",
    "    std = np.std(inputData, axis = 0)\n",
    "    normalizedData = (inputData - mean) / std\n",
    "    \n",
    "    return normalizedData\n",
    "\n",
    "def DataShuffle(dataSize):\n",
    "    indices = np.arange(dataSize)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "def DataSplit(inputData, outputData):\n",
    "    # Define the split ratio\n",
    "    trainRatio = 0.8\n",
    "    trainSize = int(len(inputData) * trainRatio)\n",
    "    \n",
    "    # Split the data\n",
    "    trainData = inputData[:trainSize]\n",
    "    trainLabel = outputData[:trainSize]\n",
    "    \n",
    "    testData = inputData[trainSize:]\n",
    "    testLabel = outputData[trainSize:]\n",
    "    \n",
    "    return trainData, trainLabel, testData, testLabel\n",
    "\n",
    "def zeroOneLoss(trueLabels, predLabels):\n",
    "    return np.sum(trueLabels != predLabels) / len(trueLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fefdb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "X_normalized = DataNormalize(X)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = DataShuffle(X.shape[0])\n",
    "X_normalized = X_normalized[indices]\n",
    "Y = Y[indices]\n",
    "    \n",
    "    \n",
    "# Split the data\n",
    "trainData, trainLabel, testData, testLabel = DataSplit(X_normalized, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b088d6c",
   "metadata": {},
   "source": [
    "# Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc9a35b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPegasosSVM:\n",
    "    def __init__(self, kernel='gaussian', _lambda=1e-4, gamma=0.1, degree=3, coef0=1, max_iter=1000):\n",
    "        self.kernel = kernel\n",
    "        self.max_iter = max_iter\n",
    "        self._lambda = _lambda\n",
    "        self.gamma = gamma\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.max_iter = max_iter\n",
    "        self.alphas = None\n",
    "        self.support_vectors = None\n",
    "        self.support_vector_labels = None\n",
    "        self.X_train = None\n",
    "        \n",
    "    def _kernel_function(self, x1, x2):\n",
    "        if self.kernel == 'gaussian':\n",
    "            return np.exp(-self.gamma * np.linalg.norm(x1 - x2) ** 2)\n",
    "        elif self.kernel == 'polynomial':\n",
    "            return (self.gamma * np.dot(x1, x2) + self.coef0) ** self.degree\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown kernel: {self.kernel}\")\n",
    "            \n",
    "    def _compute_kernel_matrix(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i, j] = self._kernel_function(X[i], X[j])\n",
    "        return K\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.alphas = np.zeros(n_samples)\n",
    "        self.X_train = X\n",
    "        K = self._compute_kernel_matrix(X)\n",
    "        \n",
    "        for t in range(1, self.max_iter + 1):\n",
    "            eta_t = 1 / (self._lambda * t)\n",
    "            i = np.random.randint(0, n_samples)\n",
    "            condition = Y[i] * np.sum(self.alphas * Y * K[:, i]) < 1\n",
    "            if condition:\n",
    "                self.alphas[i] = (1 - eta_t * self._lambda) * self.alphas[i] + eta_t\n",
    "            else:\n",
    "                self.alphas[i] = (1 - eta_t * self._lambda) * self.alphas[i]\n",
    "        \n",
    "        support_vector_indices = np.where(self.alphas > 1e-5)[0]\n",
    "        self.support_vectors = X[support_vector_indices]\n",
    "        self.support_vector_labels = Y[support_vector_indices]\n",
    "        self.alphas = self.alphas[support_vector_indices]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            kernel_sum = 0\n",
    "            for alpha, sv_y, sv in zip(self.alphas, self.support_vector_labels, self.support_vectors):\n",
    "                kernel_sum += alpha * sv_y * self._kernel_function(sv, X[i])\n",
    "            pred[i] = np.sign(kernel_sum)\n",
    "        \n",
    "        return pred\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2be1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search using Cross Validateion\n",
    "def crossValScore(X, y, params, k = 5):\n",
    "    fold_size = len(X) // k\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        \n",
    "        X_test = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_test = y[i * fold_size:(i + 1) * fold_size]\n",
    "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
    "\n",
    "        kernelPegasosSVM = KernelPegasosSVM(kernel = params['kernel'], _lambda = params['_lambda'], gamma = params['gamma'], degree =  params['degree'], coef0 = params['coef0'], max_iter =  params['max_iter'])\n",
    "        \n",
    "        kernelPegasosSVM.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = kernelPegasosSVM.predict(X_test)\n",
    "        accuracy = zeroOneLoss(predictions, y_test)\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b17d4",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cd1eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Tuning Hyperparameters for Gaussian Kernel: \n",
      "\n",
      "\n",
      "lambda: 1e-05, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.2927\n",
      "\n",
      "lambda: 1e-06, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3215\n",
      "\n",
      "lambda: 1e-07, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3765\n",
      "\n",
      "lambda: 1e-05, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3146\n",
      "\n",
      "lambda: 1e-06, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2933\n",
      "\n",
      "lambda: 1e-07, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2695\n",
      "\n",
      "lambda: 1e-05, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2980\n",
      "\n",
      "lambda: 1e-06, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2689\n",
      "\n",
      "lambda: 1e-07, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2724\n",
      "\n",
      "lambda: 1e-05, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.2817\n",
      "\n",
      "lambda: 1e-06, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3243\n",
      "\n",
      "lambda: 1e-07, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3215\n",
      "\n",
      "lambda: 1e-05, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2239\n",
      "\n",
      "lambda: 1e-06, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2436\n",
      "\n",
      "lambda: 1e-07, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2261\n",
      "\n",
      "lambda: 1e-05, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2201\n",
      "\n",
      "lambda: 1e-06, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2179\n",
      "\n",
      "lambda: 1e-07, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2033\n",
      "\n",
      "lambda: 1e-05, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.2946\n",
      "\n",
      "lambda: 1e-06, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.2739\n",
      "\n",
      "lambda: 1e-07, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.2758\n",
      "\n",
      "lambda: 1e-05, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2170\n",
      "\n",
      "lambda: 1e-06, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2117\n",
      "\n",
      "lambda: 1e-07, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2136\n",
      "\n",
      "lambda: 1e-05, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.1776\n",
      "\n",
      "lambda: 1e-06, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.1851\n",
      "\n",
      "lambda: 1e-07, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.1832\n",
      "\n",
      "Best Hyperparameters:\n",
      "\n",
      "Gaussian: \n",
      "\t lambda: 1e-05\n",
      "\t gamma: 10\n",
      "\t max_iters: 10000\n",
      "\t Best Cross-Validation loss: 0.17761100687929957\n",
      "------------------------------------------------------------\n",
      "Tuning Hyperparameters for Polynomial Kernel: \n",
      "\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3831\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3793\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3765\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2896\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3627\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3030\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2880\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3512\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3102\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4415\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4306\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4515\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.4218\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3881\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3912\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3602\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3956\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3164\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4221\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4321\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4215\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3799\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.4059\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.4190\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3827\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.4053\n",
      "\n",
      "degree: 2, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3546\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3737\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3724\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4184\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3136\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3533\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2921\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2936\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2592\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3152\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4106\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3774\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3715\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3499\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3468\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2999\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2842\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2383\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3014\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3924\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4124\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4700\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3946\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3715\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.4140\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3737\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.4078\n",
      "\n",
      "degree: 2, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3599\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4225\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4006\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3637\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3515\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3493\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3474\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3349\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3005\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3349\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4572\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3521\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3505\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3240\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3990\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3724\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3049\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2852\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2536\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3762\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4149\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4021\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3274\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3637\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3261\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2633\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2861\n",
      "\n",
      "degree: 2, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3218\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3405\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3793\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3352\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3227\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3371\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3202\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2905\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2892\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2858\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3621\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3712\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3806\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3665\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3530\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3455\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3412\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3612\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3612\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4065\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3465\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3987\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3634\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3615\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3546\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3277\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3399\n",
      "\n",
      "degree: 3, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3424\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3293\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3274\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3074\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3027\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2761\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2927\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2770\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2573\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2739\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3496\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3852\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3902\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3218\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3174\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3174\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3080\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2892\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3221\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3881\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3612\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3906\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3749\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3224\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3374\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3336\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3355\n",
      "\n",
      "degree: 3, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3609\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3615\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3577\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3777\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3118\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3330\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3152\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3121\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3161\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3111\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3480\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3533\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3734\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2855\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2702\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2608\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2914\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2442\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2749\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3859\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3705\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3380\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3130\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3049\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3130\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3033\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3177\n",
      "\n",
      "degree: 3, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2839\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3780\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3590\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3737\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3183\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2958\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2836\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2677\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2298\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2430\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3831\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3984\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4099\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3377\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3477\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3371\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3043\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3430\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3177\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4065\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4190\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4171\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3787\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3840\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3612\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3512\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3189\n",
      "\n",
      "degree: 4, coef0: 0.1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3515\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3699\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3443\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3609\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2817\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3114\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2886\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2395\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2395\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2552\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3471\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3859\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3474\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2633\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2483\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2683\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2026\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2480\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2079\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4106\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3952\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3893\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3577\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3521\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3765\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3227\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3386\n",
      "\n",
      "degree: 4, coef0: 1, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3014\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4034\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3840\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3859\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3236\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3193\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3071\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3402\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.3036\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 0.1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2974\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3271\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3399\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3693\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2955\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2861\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.3152\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2645\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2611\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 1, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2624\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3346\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.3430\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 100, \n",
      "\t\t\t\tCross Validation Loss:0.4006\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2921\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2827\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 1000, \n",
      "\t\t\t\tCross Validation Loss:0.2899\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2370\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2330\n",
      "\n",
      "degree: 4, coef0: 10, gamma: 10, n_iters: 10000, \n",
      "\t\t\t\tCross Validation Loss:0.2092\n",
      "------------------------------------------------------------\n",
      "\n",
      "Polynomial: \n",
      "\t lambda: 1e-05\n",
      "\t degree: 4\n",
      "\t gamma: 1\n",
      "\t coef0: 1\n",
      "\t max_iters: 10000\n",
      "\t Best Cross-Validation loss: 0.20262664165103192\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "lambda_values = [1e-5, 1e-6, 1e-7]\n",
    "\n",
    "# Gaussian kernel parameters:\n",
    "gamma_values = [0.1, 1, 10]\n",
    "max_iter_values = [100, 1000, 10000]\n",
    "\n",
    "# Polynomial kernel parameters\n",
    "degree_values = [2, 3, 4]\n",
    "coef0_values = [0.1, 1, 10]\n",
    "\n",
    "inputData = trainData[: int(0.4 * len(trainData))]\n",
    "outputData = trainLabel[: int(0.4 * len(trainLabel))]\n",
    "\n",
    "def evaluate_params(params):\n",
    "    mean_loss = crossValScore(inputData, outputData, params, k=3)\n",
    "    return params, mean_loss\n",
    "\n",
    "# Gaussian kernel\n",
    "print(\"-\" * 60)\n",
    "print(\"Tuning Hyperparameters for Gaussian Kernel: \\n\")\n",
    "best_gaussian_loss = 2\n",
    "best_gaussian_params = {}\n",
    "\n",
    "# Generate parameter combinations for Gaussian kernel\n",
    "gaussian_params_list = [{'kernel': 'gaussian', '_lambda': _lambda, 'gamma': gamma, 'degree': 3, 'coef0': 1.0, 'max_iter': iters}\n",
    "                        for gamma in gamma_values \n",
    "                        for iters in max_iter_values \n",
    "                        for _lambda in lambda_values]\n",
    "\n",
    "# Evaluate all parameter combinations in parallel\n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_params)(params) for params in gaussian_params_list)\n",
    "\n",
    "for params, mean_loss in results:\n",
    "    print(f\"\\nlambda: {params['_lambda']}, gamma: {params['gamma']}, n_iters: {params['max_iter']}, \\n\\t\\t\\t\\tCross Validation Loss:{mean_loss:.4f}\")\n",
    "    if mean_loss < best_gaussian_loss:\n",
    "        best_gaussian_loss = mean_loss\n",
    "        best_gaussian_params = params\n",
    "\n",
    "print(\"\\nBest Hyperparameters:\\n\")\n",
    "print(\"Gaussian: \")\n",
    "print(f\"\\t lambda: {best_gaussian_params['_lambda']}\")\n",
    "print(f\"\\t gamma: {best_gaussian_params['gamma']}\")\n",
    "print(f\"\\t max_iters: {best_gaussian_params['max_iter']}\")\n",
    "print(f\"\\t Best Cross-Validation loss: {best_gaussian_loss}\")\n",
    "\n",
    "# Polynomial Kernel\n",
    "print(\"-\" * 60)\n",
    "print(\"Tuning Hyperparameters for Polynomial Kernel: \\n\")\n",
    "best_polynomial_loss = 2\n",
    "best_polynomial_params = {} \n",
    "\n",
    "# Generate parameter combinations for Polynomial kernel\n",
    "polynomial_params_list = [{'kernel': 'polynomial', '_lambda': _lambda, 'gamma': gamma, 'degree': degree, 'coef0': coef0, 'max_iter': iters}\n",
    "                          for degree in degree_values \n",
    "                          for coef0 in coef0_values\n",
    "                          for gamma in gamma_values \n",
    "                          for iters in max_iter_values\n",
    "                          for _lambda in lambda_values]\n",
    "\n",
    "# Evaluate all parameter combinations in parallel\n",
    "results = Parallel(n_jobs=-1)(delayed(evaluate_params)(params) for params in polynomial_params_list)\n",
    "\n",
    "for params, mean_loss in results:\n",
    "    print(f\"\\ndegree: {params['degree']}, coef0: {params['coef0']}, gamma: {params['gamma']}, n_iters: {params['max_iter']}, \\n\\t\\t\\t\\tCross Validation Loss:{mean_loss:.4f}\")\n",
    "    if mean_loss < best_polynomial_loss:\n",
    "        best_polynomial_loss = mean_loss\n",
    "        best_polynomial_params = params\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"\\nPolynomial: \")\n",
    "print(f\"\\t lambda: {best_polynomial_params['_lambda']}\")\n",
    "print(f\"\\t degree: {best_polynomial_params['degree']}\")\n",
    "print(f\"\\t gamma: {best_polynomial_params['gamma']}\")\n",
    "print(f\"\\t coef0: {best_polynomial_params['coef0']}\")\n",
    "print(f\"\\t max_iters: {best_polynomial_params['max_iter']}\")\n",
    "print(f\"\\t Best Cross-Validation loss: {best_polynomial_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38467b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'gaussian',\n",
       " '_lambda': 1e-05,\n",
       " 'gamma': 10,\n",
       " 'degree': 3,\n",
       " 'coef0': 1.0,\n",
       " 'max_iter': 10000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gaussian_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39dbe8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = best_gaussian_params\n",
    "\n",
    "kernelPegasosSVM = KernelPegasosSVM(kernel = params['kernel'], _lambda = params['_lambda'], gamma = params['gamma'], degree =  params['degree'], coef0 = params['coef0'], max_iter =  params['max_iter'])\n",
    "kernelPegasosSVM.fit(trainData, trainLabel)\n",
    "\n",
    "\n",
    "preds = kernelPegasosSVM.predict(testData)\n",
    "zeroOneLoss(preds, testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba935f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2155"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = best_polynomial_params\n",
    "\n",
    "kernelPegasosSVM = KernelPegasosSVM(kernel = params['kernel'], _lambda = params['_lambda'], gamma = params['gamma'], degree =  params['degree'], coef0 = params['coef0'], max_iter =  params['max_iter'])\n",
    "kernelPegasosSVM.fit(trainData, trainLabel)\n",
    "\n",
    "preds = kernelPegasosSVM.predict(testData)\n",
    "zeroOneLoss(preds, testLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c64eea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'polynomial',\n",
       " '_lambda': 1e-05,\n",
       " 'gamma': 1,\n",
       " 'degree': 4,\n",
       " 'coef0': 1,\n",
       " 'max_iter': 10000}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_polynomial_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
