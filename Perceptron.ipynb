{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc7273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a894db6f",
   "metadata": {},
   "source": [
    "# Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ff8c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49398bcd",
   "metadata": {},
   "source": [
    "# Preparing data:\n",
    "1. Seperating features and labels\n",
    "2. Normalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43e348ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataNormalize(inputData):\n",
    "    mean = np.mean(inputData, axis = 0)\n",
    "    std = np.std(inputData, axis = 0)\n",
    "    normalizedData = (inputData - mean) / std\n",
    "    \n",
    "    return normalizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b772744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataShuffle(dataSize):\n",
    "    indices = np.arange(dataSize)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f7bfcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSplit(inputData, outputData):\n",
    "    # Define the split ratio\n",
    "    trainRatio = 0.8\n",
    "    trainSize = int(len(inputData) * trainRatio)\n",
    "    \n",
    "    # Split the data\n",
    "    trainData = inputData[:trainSize]\n",
    "    trainLabel = outputData[:trainSize]\n",
    "    testData = inputData[trainSize:]\n",
    "    testLabel = outputData[trainSize:]\n",
    "    \n",
    "    return trainData, trainLabel, testData, testLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8288fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "X_normalized = DataNormalize(X)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = DataShuffle(X.shape[0])\n",
    "X_normalized = X_normalized[indices]\n",
    "Y = Y[indices]\n",
    "    \n",
    "    \n",
    "# Split the data\n",
    "trainData, trainLabel, testData, testLabel = DataSplit(X_normalized, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038de92",
   "metadata": {},
   "source": [
    "# Perceptron Implementation \n",
    "### \"Improving the performance using Multiprocessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbc9d6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, n_iters = 1000):\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        \n",
    "    def fit(self, inputData, labelData):\n",
    "        numSamples, numFeatures = inputData.shape\n",
    "        self.weights = np.zeros(numFeatures)\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            linearOutput = np.dot(inputData, self.weights) * labelData\n",
    "            misclassified = (labelData * linearOutput) <= 0\n",
    "\n",
    "            if not np.any(misclassified):\n",
    "                break\n",
    "\n",
    "            # Update the weights by summing over all misclassified examples\n",
    "            self.weights += np.dot(labelData[misclassified], inputData[misclassified])\n",
    "                \n",
    "    def predict(self, inputData):\n",
    "        linearOutput = np.dot(inputData, self.weights)\n",
    "        pred = self._activation_function(linearOutput)\n",
    "        return pred\n",
    "    \n",
    "    def _activation_function(self, inputData):\n",
    "        return np.where(inputData >= 0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70ffe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroOneLoss(trueLabels, predLabels):\n",
    "    return np.sum(trueLabels != predLabels) / len(trueLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f243c",
   "metadata": {},
   "source": [
    "# Cross Validation Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f47079f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search using Cross Validateion\n",
    "def crossValScore(X, y, iters, k = 5):\n",
    "    fold_size = len(X) // k\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        X_test = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_test = y[i * fold_size:(i + 1) * fold_size]\n",
    "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
    "        \n",
    "        perceptron = Perceptron(iters)\n",
    "        \n",
    "        perceptron.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = perceptron.predict(X_test)\n",
    "        accuracy = zeroOneLoss(predictions, y_test)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609bfda",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45689ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iters: 100, Cross Validation Loss:0.312\n",
      "n_iters: 1000, Cross Validation Loss:0.31275\n",
      "n_iters: 1500, Cross Validation Loss:0.312625\n",
      "n_iters: 2000, Cross Validation Loss:0.312625\n",
      "n_iters: 2500, Cross Validation Loss:0.312625\n",
      "\n",
      "Best Hyperparameters:\n",
      "n_iters: 100\n",
      "Best Cross-Validation loss: 0.312\n"
     ]
    }
   ],
   "source": [
    "# Tuning Hyperparameters\n",
    "n_iters_list = [100, 1000, 1500, 2000, 2500]\n",
    "\n",
    "best_loss = 2\n",
    "best_params = {}\n",
    "\n",
    "for n_iters in n_iters_list:\n",
    "    params = {'n_iters': n_iters}\n",
    "    mean_loss = crossValScore(trainData, trainLabel,params['n_iters'], k = 5)\n",
    "    print(f\"n_iters: {n_iters}, Cross Validation Loss:{mean_loss}\")\n",
    "        \n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = mean_loss\n",
    "        best_params = params\n",
    "            \n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"n_iters: {best_params['n_iters']}\")\n",
    "print(f\"Best Cross-Validation loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4a5de",
   "metadata": {},
   "source": [
    "# Running the model using the tuned hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86dd782a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-One Loss: 0.299\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Perceptron\n",
    "perceptron = Perceptron(n_iters = best_params['n_iters'])\n",
    "\n",
    "# Train the Perceptron\n",
    "perceptron.fit(trainData, trainLabel)\n",
    "\n",
    "# Predict on the test set\n",
    "predLabels = perceptron.predict(testData)\n",
    "\n",
    "# Calculate zero-one loss\n",
    "loss = zeroOneLoss(testLabel, predLabels)\n",
    "\n",
    "print(f\"Zero-One Loss: {loss}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
