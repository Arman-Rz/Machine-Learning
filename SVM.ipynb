{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a894db6f",
   "metadata": {},
   "source": [
    "# Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ff8c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49398bcd",
   "metadata": {},
   "source": [
    "# Preparing data:\n",
    "1. Seperating features and labels\n",
    "2. Normalizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43e348ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataNormalize(inputData):\n",
    "    mean = np.mean(inputData, axis = 0)\n",
    "    std = np.std(inputData, axis = 0)\n",
    "    normalizedData = (inputData - mean) / std\n",
    "    \n",
    "    return normalizedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b772744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataShuffle(dataSize):\n",
    "    indices = np.arange(dataSize)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f7bfcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataSplit(inputData, outputData):\n",
    "    # Define the split ratio\n",
    "    trainRatio = 0.8\n",
    "    trainSize = int(len(inputData) * trainRatio)\n",
    "    \n",
    "    # Split the data\n",
    "    trainData = inputData[:trainSize]\n",
    "    trainLabel = outputData[:trainSize]\n",
    "    testData = inputData[trainSize:]\n",
    "    testLabel = outputData[trainSize:]\n",
    "    \n",
    "    return trainData, trainLabel, testData, testLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8288fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, -1].values\n",
    "\n",
    "X_normalized = DataNormalize(X)\n",
    "\n",
    "# Shuffle the data\n",
    "indices = DataShuffle(X.shape[0])\n",
    "X_normalized = X_normalized[indices]\n",
    "Y = Y[indices]\n",
    "    \n",
    "    \n",
    "# Split the data\n",
    "trainData, trainLabel, testData, testLabel = DataSplit(X_normalized, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabce774",
   "metadata": {},
   "source": [
    "# Support Vector Machines Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef2bb579",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PegasosSVM:\n",
    "    def __init__(self, lambda_param = 0.01, max_iter = 1000):\n",
    "        self.lambda_param = lambda_param\n",
    "        self.max_iter = max_iter\n",
    "        self.weights = None\n",
    "        \n",
    "    def _hinge_loss(self, X, y, w, lambda_param):\n",
    "        hinge_loss = np.maximum(0, 1 - y * (X @ w)).mean()\n",
    "        return 0.5 * lambda_param * np.dot(w, w) + hinge_loss\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        \n",
    "        for t in range(1, self.max_iter + 1):\n",
    "            eta = 1 / (self.lambda_param * t)\n",
    "            i = np.random.randint(n_samples)\n",
    "            xi, yi = X[i], y[i]\n",
    "            \n",
    "            if yi * np.dot(xi, self.weights) < 1:\n",
    "                self.weights = (1 - eta * self.lambda_param) * self.weights + eta * yi * xi\n",
    "            else:\n",
    "                self.weights = (1 - eta * self.lambda_param) * self.weights\n",
    "            \n",
    "            if t % 100 == 0:\n",
    "                loss = self._hinge_loss(X, y, self.weights, self.lambda_param)\n",
    "                #print(f\"Iteration {t}/{self.max_iter}: Loss = {loss:.4f}\")\n",
    "                \n",
    "    def predict(self, X):\n",
    "        return np.sign(X @ self.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f243c",
   "metadata": {},
   "source": [
    "# Cross Validation Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f47079f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search using Cross Validateion\n",
    "def crossValScore(X, y, params, k = 5):\n",
    "    fold_size = len(X) // k\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        X_test = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_test = y[i * fold_size:(i + 1) * fold_size]\n",
    "        X_train = np.concatenate((X[:i * fold_size], X[(i + 1) * fold_size:]), axis=0)\n",
    "        y_train = np.concatenate((y[:i * fold_size], y[(i + 1) * fold_size:]), axis=0)\n",
    "        \n",
    "        model = PegasosSVM(lambda_param = params['lambda'], max_iter = params['iters'])\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = zeroOneLoss(predictions, y_test)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70ffe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroOneLoss(trueLabels, predLabels):\n",
    "    return np.sum(trueLabels != predLabels) / len(trueLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609bfda",
   "metadata": {},
   "source": [
    "# tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "45689ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda: 0.001, n_iters: 1000, Cross Validation Loss:0.4026\n",
      "lambda: 0.001, n_iters: 1500, Cross Validation Loss:0.3862\n",
      "lambda: 0.001, n_iters: 2000, Cross Validation Loss:0.3580\n",
      "lambda: 0.01, n_iters: 1000, Cross Validation Loss:0.3134\n",
      "lambda: 0.01, n_iters: 1500, Cross Validation Loss:0.3256\n",
      "lambda: 0.01, n_iters: 2000, Cross Validation Loss:0.3031\n",
      "lambda: 0.1, n_iters: 1000, Cross Validation Loss:0.2854\n",
      "lambda: 0.1, n_iters: 1500, Cross Validation Loss:0.2861\n",
      "lambda: 0.1, n_iters: 2000, Cross Validation Loss:0.2812\n",
      "\n",
      "Best Hyperparameters:\n",
      "lambda: 0.1\n",
      "n_iters: 2000\n",
      "Best Cross-Validation loss: 0.2812\n"
     ]
    }
   ],
   "source": [
    "# Tuning Hyperparameters\n",
    "lambda_list = [0.001, 0.01, 0.1]\n",
    "n_iters_list = [1000, 1500, 2000]\n",
    "\n",
    "best_loss = 2\n",
    "best_params = {}\n",
    "for lambdas in lambda_list:\n",
    "    for n_iters in n_iters_list:\n",
    "        params = {'lambda': lambdas,'iters': n_iters}\n",
    "        mean_loss = crossValScore(trainData, trainLabel,params, k = 5)\n",
    "        print(f\"lambda: {lambdas}, n_iters: {n_iters}, Cross Validation Loss:{mean_loss:.4f}\")\n",
    "\n",
    "        if mean_loss < best_loss:\n",
    "            best_loss = mean_loss\n",
    "            best_params = params\n",
    "            \n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "print(f\"lambda: {best_params['lambda']}\")\n",
    "print(f\"n_iters: {best_params['iters']}\")\n",
    "print(f\"Best Cross-Validation loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86dd782a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - Zero-One Loss: 0.275\n",
      "Iteration 2 - Zero-One Loss: 0.2975\n",
      "Iteration 3 - Zero-One Loss: 0.2845\n",
      "Iteration 4 - Zero-One Loss: 0.2895\n",
      "Iteration 5 - Zero-One Loss: 0.29\n",
      "Iteration 6 - Zero-One Loss: 0.2725\n",
      "Iteration 7 - Zero-One Loss: 0.2735\n",
      "Iteration 8 - Zero-One Loss: 0.28\n",
      "Iteration 9 - Zero-One Loss: 0.2885\n",
      "Iteration 10 - Zero-One Loss: 0.278\n",
      "Average Zero-One Loss: 0.2829\n"
     ]
    }
   ],
   "source": [
    "numberOfRuns = 10\n",
    "losses = []\n",
    "\n",
    "for i in range(numberOfRuns):\n",
    "    # Shuffle the data\n",
    "    indices = DataShuffle(trainData.shape[0])\n",
    "    trainData = trainData[indices]\n",
    "    trainLabel = trainLabel[indices]\n",
    "\n",
    "    # Initialize the SVM Model\n",
    "    model = PegasosSVM(lambda_param = best_params['lambda'], max_iter = best_params['iters'])\n",
    "\n",
    "    # Train the Perceptron\n",
    "    model.fit(trainData, trainLabel)\n",
    "\n",
    "    # Predict on the test set\n",
    "    predLabels = model.predict(testData)\n",
    "\n",
    "    # Calculate zero-one loss\n",
    "    loss = zeroOneLoss(testLabel, predLabels)\n",
    "    print(f\"Iteration {i + 1} - Zero-One Loss: {loss}\")\n",
    "    losses.append(loss)\n",
    "\n",
    "averageLoss = np.mean(losses)\n",
    "print(f\"Average Zero-One Loss: {averageLoss:.4f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
